(define-module (crates-io sy nt syntaxdot-tokenizers) #:use-module (crates-io))

(define-public crate-syntaxdot-tokenizers-0.2.0 (c (n "syntaxdot-tokenizers") (v "0.2.0") (d (list (d (n "conllu") (r "^0.5") (d #t) (k 0)) (d (n "ndarray") (r "^0.13") (d #t) (k 0)) (d (n "sentencepiece") (r "^0.5") (d #t) (k 0)) (d (n "thiserror") (r "^1") (d #t) (k 0)) (d (n "wordpieces") (r "^0.4") (d #t) (k 0)))) (h "1fb5r4ydmlgcf5hcnfp7b91cg5m8gmr28xpxwk6b6wm99h223qr4") (f (quote (("model-tests"))))))

(define-public crate-syntaxdot-tokenizers-0.2.1 (c (n "syntaxdot-tokenizers") (v "0.2.1") (d (list (d (n "conllu") (r "^0.5") (d #t) (k 0)) (d (n "ndarray") (r "^0.13") (d #t) (k 0)) (d (n "sentencepiece") (r "^0.5") (d #t) (k 0)) (d (n "thiserror") (r "^1") (d #t) (k 0)) (d (n "wordpieces") (r "^0.4") (d #t) (k 0)))) (h "01hg9hxqqzkbx6d9z8b0ih6nlzdqmi9hgsvn2g2qrxmgpxnncddm") (f (quote (("model-tests"))))))

(define-public crate-syntaxdot-tokenizers-0.3.0 (c (n "syntaxdot-tokenizers") (v "0.3.0") (d (list (d (n "ndarray") (r "^0.14") (d #t) (k 0)) (d (n "sentencepiece") (r "^0.6") (d #t) (k 0)) (d (n "thiserror") (r "^1") (d #t) (k 0)) (d (n "udgraph") (r "^0.6") (d #t) (k 0)) (d (n "wordpieces") (r "^0.4") (d #t) (k 0)))) (h "1qkxl4fxawndqds4ii1qmv03ld2s7v8dyicshdmn1y37b8v4r4wl") (f (quote (("model-tests"))))))

(define-public crate-syntaxdot-tokenizers-0.4.0 (c (n "syntaxdot-tokenizers") (v "0.4.0") (d (list (d (n "ndarray") (r "^0.15") (d #t) (k 0)) (d (n "sentencepiece") (r "^0.8") (d #t) (k 0)) (d (n "thiserror") (r "^1") (d #t) (k 0)) (d (n "udgraph") (r "^0.7") (d #t) (k 0)) (d (n "wordpieces") (r "^0.5") (d #t) (k 0)))) (h "17k7caw38m4fiw5mpqfq9mnhy3zf9ijvfj9hcavnxp6rbr4x0rjb") (f (quote (("model-tests"))))))

(define-public crate-syntaxdot-tokenizers-0.5.0-beta.0 (c (n "syntaxdot-tokenizers") (v "0.5.0-beta.0") (d (list (d (n "ndarray") (r "^0.15") (d #t) (k 0)) (d (n "sentencepiece") (r "^0.8") (d #t) (k 0)) (d (n "thiserror") (r "^1") (d #t) (k 0)) (d (n "udgraph") (r "^0.8") (d #t) (k 0)) (d (n "wordpieces") (r "^0.5") (d #t) (k 0)))) (h "0xvb32gfkx9q65xr7snj5jsywwvj6w15qs33yfcbhpicqjh7jh4n") (f (quote (("model-tests"))))))

(define-public crate-syntaxdot-tokenizers-0.5.0-beta.1 (c (n "syntaxdot-tokenizers") (v "0.5.0-beta.1") (d (list (d (n "ndarray") (r "^0.15") (d #t) (k 0)) (d (n "sentencepiece") (r "^0.8") (d #t) (k 0)) (d (n "thiserror") (r "^1") (d #t) (k 0)) (d (n "udgraph") (r "^0.8") (d #t) (k 0)) (d (n "wordpieces") (r "^0.5") (d #t) (k 0)))) (h "0ibbgdx2k587w64cj3jwv1pr2yq38y36zhfxmbd8d8dazzfhc97k") (f (quote (("model-tests"))))))

(define-public crate-syntaxdot-tokenizers-0.5.0-beta.2 (c (n "syntaxdot-tokenizers") (v "0.5.0-beta.2") (d (list (d (n "ndarray") (r "^0.15") (d #t) (k 0)) (d (n "sentencepiece") (r "^0.8") (d #t) (k 0)) (d (n "thiserror") (r "^1") (d #t) (k 0)) (d (n "udgraph") (r "^0.8") (d #t) (k 0)) (d (n "wordpieces") (r "^0.5") (d #t) (k 0)))) (h "19pjxqq1ysb2cjiai60fl5ii60gy9fm27cf0k4swlwkglbyl4qiy") (f (quote (("model-tests"))))))

(define-public crate-syntaxdot-tokenizers-0.5.0 (c (n "syntaxdot-tokenizers") (v "0.5.0") (d (list (d (n "ndarray") (r "^0.15") (d #t) (k 0)) (d (n "sentencepiece") (r "^0.11") (d #t) (k 0)) (d (n "thiserror") (r "^1") (d #t) (k 0)) (d (n "udgraph") (r "^0.8") (d #t) (k 0)) (d (n "wordpieces") (r "^0.5") (d #t) (k 0)))) (h "1h1wq8lh4rbf36aclf7ny6zim6prh4dwp4z3ajpgph29hxg6na7i") (f (quote (("model-tests"))))))

